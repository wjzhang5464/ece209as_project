# Abstract

This project is aimed at detecting forged multimedia contents generated by DeepFake techniques. The detection is realized with a deep learning network inspired by Siamese Network arthitecture and trained with affective cues, i.e., audio and visual modalities from the examined video. As a novelty and an attempt to improve accuracy of detection, we combine other features such as lip movement or eye-blinking as a support. In the original paper that inspired us, the result shows that the accuracy is as high as 96.3% and 84.4% for DF-TIMIT and DFDC datasets, respectively.


# Team

* Ruoye Wang
* Jinchen Wu
* Weijian Zhang

# Required Submissions

* [Proposal](proposal)
* [Midterm Checkpoint Presentation Slides](https://drive.google.com/file/d/1qdEVNqvM_UC80J00VxgYIKhfdK6g3pvv/view?usp=sharing)
* [Final Presentation Slides](https://drive.google.com/file/d/1TGB-t0v-eDpkHbBC7k940xxZLaeFMlMe/view?usp=sharing)
* [Final Report](report)
