# Abstract

This project is aimed at detecting forged multimedia contents generated by DeepFake techniques. The detection is realized with a deep learning network inspired by Siamese Network arthitecture and trained with affective cues, i.e., audio and visual modalities from the examined video. As a novelty and an attempt to improve accuracy of detection, we combine other features such as lip movement or eye-blinking as a support. In the original paper that inspired us, the result shows that the accuracy is as high as 96.3% and 84.4% for DF-TIMIT and DFDC datasets, respectively.


# Team

* Ruoye Wang
* Jinchen Wu
* Weijian Zhang

# Required Submissions

* [Proposal](proposal)
* [Midterm Checkpoint Presentation Slides](Midterm Checkpoint Presentation Slides.pdf)
* [Final Presentation Slides](Final Presentation Slides.pdf)
* [Final Report](report)
